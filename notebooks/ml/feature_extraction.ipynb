{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.13 (you have 1.4.8). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "sys.path.append('../..')\n",
    "from torch.utils.data import DataLoader\n",
    "from src.training.train import load_config,create_transfroms,create_model,Collate\n",
    "from src.datasets import ISICDataset\n",
    "from src.utils import *\n",
    "from definitions import *\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPIREMENT = 'efficientnet_b0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = load_config(EXPIREMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(expirement_name : str) -> list:\n",
    "    \n",
    "\n",
    "    expirement_dir = os.path.join(EXPIREMENTS_DIR,expirement_name)\n",
    "    checkpoints_dir = os.path.join(expirement_dir,'checkpoints')\n",
    "\n",
    "    models = []\n",
    "\n",
    "    files = os.listdir(checkpoints_dir)\n",
    "    files = sorted(files,key = lambda x: int(x.split('_')[-1]))\n",
    "\n",
    "    for fold in files:\n",
    "\n",
    "        print(f'Loading model from {fold}')\n",
    "\n",
    "        fold_dir = os.path.join(checkpoints_dir,fold)\n",
    "        model_name = os.listdir(fold_dir)[0]\n",
    "\n",
    "        model_path = os.path.join(fold_dir,model_name)\n",
    "\n",
    "        model = create_model(configs)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.to(DEVICE)\n",
    "        model.eval()\n",
    "\n",
    "        models.append(model)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from fold_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._hub:[timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from fold_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._hub:[timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from fold_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._hub:[timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from fold_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._hub:[timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from fold_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._hub:[timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    }
   ],
   "source": [
    "models = load_models(EXPIREMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transfroms,val_transfroms = create_transfroms(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ISICDataset(\n",
    "    hdf5_file=os.path.join(ISIS_2024_DIR, 'images.hdf5'),\n",
    "    metadata_file=os.path.join(ISIS_2024_DIR, 'metadata.csv'),\n",
    "    img_transform=val_transfroms,\n",
    "    return_metadata=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    prefetch_factor=2,\n",
    "    collate_fn=Collate(configs, False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfroms = {\n",
    "    'rotate_0' : lambda x : x,\n",
    "    # 'rotate_90' : lambda x : torch.rot90(x,1,[2,3]),\n",
    "    # 'rotate_180' : lambda x : torch.rot90(x,2,[2,3]),\n",
    "    # 'rotate_270' : lambda x : torch.rot90(x,3,[2,3]),\n",
    "    # 'horizontal_flip' : lambda x : torch.flip(x,[3]),\n",
    "    # 'vertical_flip' : lambda x : torch.flip(x,[2]),\n",
    "    # 'horizontal_vertical_flip' : lambda x : torch.flip(x,[2,3]),\n",
    "    # 'transpose' : lambda x : torch.transpose(x,2,3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(models : list[torch.nn.Module],loader : DataLoader,transfroms : list) -> pd.DataFrame:\n",
    "    \n",
    "    df = dict()\n",
    "    df['isic_id'] = loader.dataset.metadata['isic_id'].values\n",
    "\n",
    "    for fold,_ in enumerate(models):\n",
    "        for transfrom in transfroms:\n",
    "            df[f'fold_{fold}_{transfrom}'] = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for x,y in tqdm(loader):\n",
    "\n",
    "            x = x.to(DEVICE)\n",
    "\n",
    "            for transfrom_name,transfrom in transfroms.items():\n",
    "\n",
    "                transfromed_x = transfrom(x)\n",
    "\n",
    "                for fold,model in enumerate(models):\n",
    "                    \n",
    "                    predictions = model(transfromed_x)\n",
    "\n",
    "                    df[f'fold_{fold}_{transfrom_name}'].extend(predictions.detach().cpu().numpy())\n",
    "\n",
    "    return pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04617bcb6ace4358a9131ba6c0707a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12534 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = feature_extract(models,loader,transfroms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(EXPIREMENTS_DIR,EXPIREMENT,'features.csv'),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
