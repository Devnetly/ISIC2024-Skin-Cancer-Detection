{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.14 (you have 1.4.8). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import polars as pl\n",
    "import torch\n",
    "import warnings\n",
    "import h5py\n",
    "import timm\n",
    "import io\n",
    "import os\n",
    "import albumentations as A\n",
    "import albumentations.pytorch as AP\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn,Tensor\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import OneHotEncoder,FunctionTransformer,OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer,make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import StackingClassifier,VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from pandas.errors import DtypeWarning\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from typing import Any, Callable, Optional\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore',category=UserWarning)\n",
    "warnings.filterwarnings('ignore',category=DtypeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_METADATA = '/home/abdelnour/Documents/projects/skin-cancer-detection/data/isic2024/train-metadata.csv'\n",
    "TEST_METADATA = '/home/abdelnour/Documents/projects/skin-cancer-detection/data/isic2024/test-metadata.csv'\n",
    "TEST_IMAGES = '/home/abdelnour/Documents/projects/skin-cancer-detection/data/isic2024/test-image.hdf5'\n",
    "FEATURES = '/home/abdelnour/Documents/projects/skin-cancer-detection/data/features.csv'\n",
    "EVA_FETURES = '/home/abdelnour/Documents/projects/skin-cancer-detection/data/eva.csv'\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_METADATA)\n",
    "test_df = pd.read_csv(TEST_METADATA)\n",
    "features = pd.read_csv(FEATURES)\n",
    "eva_features = pd.read_csv(EVA_FETURES)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'isic_id'\n",
    "group_col = 'patient_id'\n",
    "target_col = 'target'\n",
    "train_only_columns = train_df.columns.difference(test_df.columns).tolist()\n",
    "drop_columns = train_only_columns + [id_col,group_col,target_col]\n",
    "images_features = ['eva02','eva02_tiny_patch14_224','coat_lite_tiny_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedGroupKFold(n_splits=5,shuffle=True,random_state=SEED)\n",
    "splits = list(cv.split(X=train_df,y=train_df[target_col],groups=train_df[group_col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.merge(features,on=id_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(metadata: pd.DataFrame):\n",
    "\n",
    "    epsilon = 1e-8 # To avoid division by zero\n",
    "\n",
    "    pl_df = pl.DataFrame(metadata)\n",
    "\n",
    "    # Diameter: Melanoma growths are normally larger than 6mm in diameter, which is about the diameter of a standard pencil eraser\n",
    "\n",
    "    pl_df = pl_df.with_columns([\n",
    "        # Diameter ratio: This is a measure of how elongated the mole is. A perfectly round mole has an axis ratio of 1.0\n",
    "        pl.col('tbp_lv_minorAxisMM').truediv(pl.col('clin_size_long_diam_mm') + epsilon)\n",
    "        .cast(pl.Float32).alias('diam_ratio'),\n",
    "\n",
    "        # Diameter difference: Difference between the long diameter and minor axis\n",
    "        pl.col('clin_size_long_diam_mm').sub(pl.col('tbp_lv_minorAxisMM'))\n",
    "        .cast(pl.Float32).alias('diam_difference'),\n",
    "\n",
    "        # Long diameter greater than 6mm\n",
    "        pl.when(pl.col('clin_size_long_diam_mm') > 6).then(1.0).otherwise(0.0)\n",
    "        .cast(pl.Float32).alias('long_diam_gt_6mm'),\n",
    "\n",
    "        # Minor axis greater than 6mm\n",
    "        pl.when(pl.col('tbp_lv_minorAxisMM') > 6).then(1.0).otherwise(0.0)\n",
    "        .cast(pl.Float32).alias('short_diam_gt_6mm')\n",
    "    ])\n",
    "\n",
    "    # Evolution: Melanoma lesions often change in size, shape, color, or texture over time, while non-cancerous moles usually stay the same\n",
    "    pl_df = pl_df.with_columns([\n",
    "        # Position of the mole in the 3d space\n",
    "        (pl.col('tbp_lv_x').pow(2) + pl.col('tbp_lv_y').pow(2) + pl.col('tbp_lv_z').pow(2)).sqrt()\n",
    "        .cast(pl.Float32).alias('3d_position'),\n",
    "\n",
    "        # Perimeter area ratio\n",
    "        pl.col('tbp_lv_perimeterMM').truediv(pl.col('tbp_lv_areaMM2') + epsilon)\n",
    "        .cast(pl.Float32).alias('perim_area_ratio'),\n",
    "\n",
    "        # log area\n",
    "        pl.col('tbp_lv_areaMM2').log().cast(pl.Float32).alias('log_area'),\n",
    "\n",
    "        # log perimeter\n",
    "        pl.col('tbp_lv_perimeterMM').log().cast(pl.Float32).alias('log_perimeter'),\n",
    "\n",
    "        # Roundness: This is a measure of how round the mole is. A perfectly round mole has a roundness index of 1.0\n",
    "        pl.col('tbp_lv_areaMM2').mul(4 * np.pi).truediv(pl.col('tbp_lv_perimeterMM').pow(2) + epsilon)\n",
    "        .cast(pl.Float32).alias('roundness_index'),\n",
    "    ])\n",
    "\n",
    "    # Asymmetry: Melanoma is often asymmetrical, which means the shape isn't uniform, Non-cancerous moles are typically uniform and symmetrical\n",
    "    pl_df = pl_df.with_columns([\n",
    "        # Asymmetry angle sinus\n",
    "        pl.col('tbp_lv_symm_2axis_angle').sin()\n",
    "        .cast(pl.Float32).alias('asymmetry_angle_sin'),\n",
    "\n",
    "        # Asymmetry angle cosinus\n",
    "        pl.col('tbp_lv_symm_2axis_angle').cos()\n",
    "        .cast(pl.Float32).alias('asymmetry_angle_cos'),\n",
    "\n",
    "        # Asymmetry index\n",
    "        pl.col('tbp_lv_symm_2axis').mul(pl.col('tbp_lv_eccentricity'))\n",
    "        .cast(pl.Float32).alias('symmetry_index'),\n",
    "\n",
    "        # Symmetry border interaction\n",
    "        pl.col('tbp_lv_symm_2axis').mul(pl.col('tbp_lv_norm_border'))\n",
    "        .cast(pl.Float32).alias('symmetry_border_interaction'),\n",
    "\n",
    "        # Symmetry eccentricity interaction\n",
    "        pl.col('tbp_lv_symm_2axis').mul(pl.col('tbp_lv_eccentricity'))\n",
    "        .cast(pl.Float32).alias('symmetry_eccentricity_interaction'),\n",
    "\n",
    "        # Symmetry color interaction\n",
    "        pl.col('tbp_lv_symm_2axis').mul(pl.col('tbp_lv_radial_color_std_max'))\n",
    "        .cast(pl.Float32).alias('symmetry_color_interaction'),\n",
    "\n",
    "        # Symmetry border jaggedness interaction\n",
    "        pl.col('tbp_lv_symm_2axis').mul(pl.col('tbp_lv_area_perim_ratio'))\n",
    "        .cast(pl.Float32).alias('symmetry_border_jaggedness_interaction'),\n",
    "    ])\n",
    "\n",
    "    # Color: Melanoma lesions are often more than one color or shade, Moles that are benign are usually one color\n",
    "    pl_df = pl_df.with_columns([\n",
    "        # Color std ratio\n",
    "        pl.col('tbp_lv_color_std_mean').truediv(pl.col('tbp_lv_radial_color_std_max') + epsilon)\n",
    "        .cast(pl.Float32).alias('color_std_ratio'),\n",
    "\n",
    "        (pl.col('tbp_lv_L').sub(pl.col('tbp_lv_Lext')) + pl.col('tbp_lv_A').sub(pl.col('tbp_lv_Aext')) + pl.col('tbp_lv_B').sub(pl.col('tbp_lv_Bext')))\n",
    "        .truediv((pl.col('tbp_lv_L') + pl.col('tbp_lv_A') + pl.col('tbp_lv_B') + epsilon))\n",
    "        .cast(pl.Float32).alias('color_difference_ratio'),\n",
    "\n",
    "        (pl.col('tbp_lv_deltaA')**2 + pl.col('tbp_lv_deltaB')**2 + pl.col('tbp_lv_deltaL')**2).sqrt()\n",
    "        .cast(pl.Float32).alias('color_euclidean_distance'),\n",
    "\n",
    "        # Color eccentricity interaction\n",
    "        pl.col('tbp_lv_radial_color_std_max').mul(pl.col('tbp_lv_eccentricity'))\n",
    "        .cast(pl.Float32).alias('color_eccentricity_interaction'),\n",
    "\n",
    "        pl.col('tbp_lv_L').sub(pl.col('tbp_lv_L').mean()).truediv(pl.col('tbp_lv_stdL') + epsilon)\n",
    "        .cast(pl.Float32).alias('L_normalized'),\n",
    "\n",
    "        # H Contrast\n",
    "        pl.col('tbp_lv_H').sub(pl.col('tbp_lv_Hext'))\n",
    "        .cast(pl.Float32).alias('H_contrast'),\n",
    "\n",
    "        # L Contrast\n",
    "        pl.col('tbp_lv_L').sub(pl.col('tbp_lv_Lext'))\n",
    "        .cast(pl.Float32).alias('L_contrast'),\n",
    "\n",
    "        # A Contrast\n",
    "        pl.col('tbp_lv_A').sub(pl.col('tbp_lv_Aext'))\n",
    "        .cast(pl.Float32).alias('A_contrast'),\n",
    "\n",
    "        # B Contrast\n",
    "        pl.col('tbp_lv_B').sub(pl.col('tbp_lv_Bext'))\n",
    "        .cast(pl.Float32).alias('B_contrast'),\n",
    "\n",
    "        # C Contrast\n",
    "        pl.col('tbp_lv_C').sub(pl.col('tbp_lv_Cext'))\n",
    "        .cast(pl.Float32).alias('C_contrast'),\n",
    "\n",
    "        # A/B ratio\n",
    "        pl.col('tbp_lv_deltaA').truediv(pl.col('tbp_lv_deltaB') + epsilon)\n",
    "        .cast(pl.Float32).alias('A_B_ratio'),\n",
    "\n",
    "        # L uniformity\n",
    "        pl.col('tbp_lv_L').sub(pl.col('tbp_lv_Lext')).truediv(pl.col('tbp_lv_L') + epsilon)\n",
    "        .cast(pl.Float32).alias('L_uniformity'),\n",
    "\n",
    "        # A uniformity\n",
    "        pl.col('tbp_lv_A').sub(pl.col('tbp_lv_Aext')).truediv(pl.col('tbp_lv_A') + epsilon)\n",
    "        .cast(pl.Float32).alias('A_uniformity'),\n",
    "\n",
    "        # B uniformity\n",
    "        pl.col('tbp_lv_B').sub(pl.col('tbp_lv_Bext')).truediv(pl.col('tbp_lv_B') + epsilon)\n",
    "        .cast(pl.Float32).alias('B_uniformity'),\n",
    "\n",
    "        # C uniformity\n",
    "        pl.col('tbp_lv_C').sub(pl.col('tbp_lv_Cext')).truediv(pl.col('tbp_lv_C') + epsilon)\n",
    "        .cast(pl.Float32).alias('C_uniformity'),\n",
    "\n",
    "        # H uniformity ratio\n",
    "        pl.col('tbp_lv_H').sub(pl.col('tbp_lv_Hext')).truediv(pl.col('tbp_lv_H') + epsilon)\n",
    "        .cast(pl.Float32).alias('H_uniformity_ratio'),\n",
    "\n",
    "        pl.col('tbp_lv_deltaA').add(pl.col('tbp_lv_deltaB')).add(pl.col('tbp_lv_deltaL'))\n",
    "        .cast(pl.Float32).alias('delta_sum'),\n",
    "    ])\n",
    "\n",
    "    pl_df = pl_df.with_columns([\n",
    "        # lesions count by patient\n",
    "        pl.col('isic_id').count().over('patient_id').alias('lesions_count_by_patient'),\n",
    "        \n",
    "        (pl.col('eva02') + pl.col('eva02_tiny_patch14_224') + pl.col('coat_lite_tiny_2')).truediv(3)\n",
    "            .cast(pl.Float32).alias('image_features_ensemble')\n",
    "    ])\n",
    "\n",
    "    pd_df = pl_df.to_pandas()\n",
    "    \n",
    "    numerical_cols = pd_df.select_dtypes(np.number).columns\n",
    "\n",
    "    pl_df = pl.DataFrame(pd_df)\n",
    "\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (pl.col(col).sub(pl.col(col).mean())).truediv(pl.col(col).std() + epsilon).over('patient_id')\n",
    "            .cast(pl.Float32).alias(f'{col}_zscore') for col in numerical_cols if col != 'target'\n",
    "    ]) \\\n",
    "    .with_columns([\n",
    "        pl.col(col).min().over('patient_id').alias(f'{col}_min') for col in images_features + ['image_features_ensemble']\n",
    "    ]) \\\n",
    "    .with_columns([\n",
    "        pl.col(col).max().over('patient_id').alias(f'{col}_max') for col in images_features + ['image_features_ensemble']\n",
    "    ]) \\\n",
    "    .with_columns([\n",
    "        pl.col(col).mean().over('patient_id').alias(f'{col}_mean') for col in images_features + ['image_features_ensemble']\n",
    "    ]) \\\n",
    "    .with_columns([\n",
    "        pl.col(col).std().over('patient_id').alias(f'{col}_std') for col in images_features + ['image_features_ensemble']\n",
    "    ]) \\\n",
    "    .with_columns([\n",
    "        pl.col(col).median().over('patient_id').alias(f'{col}_median') for col in images_features + ['image_features_ensemble']\n",
    "    ]) \\\n",
    "    .with_columns([\n",
    "        pl.col(col).skew().over('patient_id').alias(f'{col}_skew') for col in images_features + ['image_features_ensemble']\n",
    "    ]) \\\n",
    "    .with_columns([\n",
    "        pl.col(col).quantile(0.25).over('patient_id').alias(f'{col}_q25') for col in images_features + ['image_features_ensemble']\n",
    "    ]) \\\n",
    "    .with_columns([\n",
    "        pl.col(col).quantile(0.75).over('patient_id').alias(f'{col}_q75') for col in images_features + ['image_features_ensemble']\n",
    "    ])\n",
    "\n",
    "    pd_df = pl_df.to_pandas()\n",
    "    \n",
    "    for col in numerical_cols:\n",
    "        pd_df[col] = pd_df[col].replace(np.inf, 1e8).replace(-np.inf, -1e8)\n",
    "\n",
    "    return pd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(\n",
    "    df : pd.DataFrame,\n",
    "    features : pd.DataFrame | None = None,\n",
    "    preprocessor : Pipeline | None = None,\n",
    ") -> tuple[tuple[pd.DataFrame,pd.Series],Pipeline]:\n",
    "    \n",
    "    X = df.drop(columns=[target_col],errors='ignore')\n",
    "    y = df[target_col] if target_col in df.columns else None\n",
    "\n",
    "    if features is not None:\n",
    "        X = X.merge(features,on=id_col)\n",
    "\n",
    "    if preprocessor is None:\n",
    "\n",
    "        transforms  = [\n",
    "            ('drop-columns-1',FunctionTransformer(lambda df: df.drop(columns=train_only_columns,errors='ignore'))),\n",
    "            ('feature-engineering',FunctionTransformer(feature_engineering)),\n",
    "            ('drop-columns-2',FunctionTransformer(lambda df: df.drop(columns=drop_columns,errors='ignore'))),\n",
    "            ('preprocessing',ColumnTransformer([\n",
    "                ('num',SimpleImputer(strategy='median'),make_column_selector(dtype_include=np.number)),\n",
    "                ('cat',OrdinalEncoder(\n",
    "                    handle_unknown='use_encoded_value',\n",
    "                    unknown_value=-1,\n",
    "                    dtype=np.int32\n",
    "                ),make_column_selector(dtype_include=pd.CategoricalDtype)),\n",
    "            ])),\n",
    "        ]\n",
    "\n",
    "        preprocessor = Pipeline(transforms).set_output(transform=\"pandas\")\n",
    "\n",
    "        preprocessor = preprocessor.fit(X,y)\n",
    "\n",
    "    X = preprocessor.transform(X)\n",
    "\n",
    "    X.columns = [\n",
    "        f'cat_col_{i}' if col.startswith('cat') else f'num_col_{i}'\n",
    "        for i,col in enumerate(X.columns)\n",
    "    ]\n",
    "\n",
    "    return (X,y),preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>eva02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015845</td>\n",
       "      <td>0.012015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0015902</td>\n",
       "      <td>0.009385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0024200</td>\n",
       "      <td>0.015275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ISIC_0051665</td>\n",
       "      <td>0.007602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ISIC_0051812</td>\n",
       "      <td>0.016717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         isic_id     eva02\n",
       "1   ISIC_0015845  0.012015\n",
       "3   ISIC_0015902  0.009385\n",
       "4   ISIC_0024200  0.015275\n",
       "7   ISIC_0051665  0.007602\n",
       "10  ISIC_0051812  0.016717"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_eva_features = []\n",
    "\n",
    "for i,(train_idx,val_idx) in enumerate(splits):\n",
    "    a = eva_features[['isic_id',f'eva02_fold{i}']].iloc[val_idx]\n",
    "    a['eva02'] = a[f'eva02_fold{i}']\n",
    "    a = a.drop(columns=[f'eva02_fold{i}'])\n",
    "    oof_eva_features.append(a)\n",
    "\n",
    "oof_eva_features = pd.concat(oof_eva_features)\n",
    "oof_eva_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(columns=[\"resnet18\",\"coat_lite_tiny\",\"swin_tiny_patch4_window7_224\"])\n",
    "features = features.merge(oof_eva_features,on='isic_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),preprocessor = prepare_data(train_df,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401059, 176)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = train_df.merge(features,on=id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pauc(df['target'],df['resnet18'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(\n",
    "    X : pd.DataFrame,\n",
    "    y : pd.Series,\n",
    "    splits : list\n",
    ") -> list[dict[str,tuple[pd.DataFrame,pd.Series]]]:\n",
    "\n",
    "    folds = []\n",
    "    \n",
    "    for train_idx,val_idx in splits:\n",
    "        \n",
    "        folds.append({\n",
    "            'train': (X.iloc[train_idx],y.iloc[train_idx]),\n",
    "            'test': (X.iloc[val_idx],y.iloc[val_idx]),\n",
    "        })\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = split(X_train,y_train, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pauc(solution: np.array, submission: np.array, min_tpr : float = 0.8) -> float:\n",
    "    \n",
    "    v_gt = abs(np.asarray(solution)-1)\n",
    "    \n",
    "    # flip the submissions to their compliments\n",
    "    v_pred = -1.0*np.asarray(submission)\n",
    "\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "\n",
    "    # using sklearn.metric functions: (1) roc_curve and (2) auc\n",
    "    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=None)\n",
    "    if max_fpr is None or max_fpr == 1:\n",
    "        return auc(fpr, tpr)\n",
    "    if max_fpr <= 0 or max_fpr > 1:\n",
    "        raise ValueError(\"Expected min_tpr in range [0, 1), got: %r\" % min_tpr)\n",
    "        \n",
    "    # Add a single point at max_fpr by linear interpolation\n",
    "    stop = np.searchsorted(fpr, max_fpr, \"right\")\n",
    "    x_interp = [fpr[stop - 1], fpr[stop]]\n",
    "    y_interp = [tpr[stop - 1], tpr[stop]]\n",
    "    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n",
    "    fpr = np.append(fpr[:stop], max_fpr)\n",
    "    partial_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return(partial_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_lgbm = 0.4\n",
    "w_xgb = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    folds : list[dict[str,tuple[pd.DataFrame,pd.Series]]],\n",
    "    params : dict,\n",
    ") -> list[float]:\n",
    "\n",
    "    models = {\n",
    "        'xgb' : [],\n",
    "        'lgb' : [],\n",
    "        'cat' : [],\n",
    "        'soft' : [],\n",
    "        'stacking' : [],\n",
    "        'max' : []\n",
    "    }\n",
    "\n",
    "    scores = {\n",
    "        'xgb' : [],\n",
    "        'lgb' : [],\n",
    "        'cat' : [],\n",
    "        'soft' : [],\n",
    "        'stacking' : [],\n",
    "        'max' : []\n",
    "    }\n",
    "\n",
    "    preds = {\n",
    "        'xgb' : [],\n",
    "        'lgb' : [],\n",
    "        'cat' : [],\n",
    "        'soft' : [],\n",
    "        'stacking' : [],\n",
    "        'max' : []\n",
    "    }\n",
    "\n",
    "    for fold_id,fold in enumerate(folds):\n",
    "        \n",
    "        ### Get the data\n",
    "        X_train,y_train = fold['train']\n",
    "        X_val,y_val = fold['test']\n",
    "\n",
    "        ### ** LGBM ** ###\n",
    "\n",
    "        ### Training\n",
    "        lgb_model = Pipeline([\n",
    "            ('sampler1', RandomOverSampler(sampling_strategy= 0.003 , random_state=SEED)),\n",
    "            ('sampler2', RandomUnderSampler(sampling_strategy=0.01, random_state=SEED)),\n",
    "            ('classifier', lgb.LGBMClassifier(**params[\"lgbm\"])),\n",
    "        ])\n",
    "\n",
    "        lgb_model.fit(X_train,y_train)\n",
    "\n",
    "        ### Predictions\n",
    "        lgb_y_pred = lgb_model.predict_proba(X_val)[:,1]\n",
    "\n",
    "        ### Evaluation\n",
    "        lgb_pauc = pauc(y_val,lgb_y_pred)\n",
    "        print(f'Fold {fold_id+1} LGBM : {lgb_pauc}')\n",
    "\n",
    "        ### ** XGB ** ###\n",
    "\n",
    "        ### Training\n",
    "        xgb_model = Pipeline([\n",
    "            ('sampler1', RandomOverSampler(sampling_strategy= 0.003 , random_state=SEED)),\n",
    "            ('sampler2', RandomUnderSampler(sampling_strategy=0.01, random_state=SEED)),\n",
    "            ('classifier', xgb.XGBClassifier(**params[\"xgb\"])),\n",
    "        ])\n",
    "        xgb_model.fit(X_train,y_train)\n",
    "\n",
    "        ### Predictions\n",
    "        xgb_y_pred = xgb_model.predict_proba(X_val)[:,1]\n",
    "\n",
    "        ### Evaluation\n",
    "        xgb_pauc = pauc(y_val,xgb_y_pred)\n",
    "        print(f'Fold {fold_id+1} XGB : {xgb_pauc}')\n",
    "\n",
    "        ### ** Cat ** ###\n",
    "\n",
    "        ### Training\n",
    "        cb_model = Pipeline([\n",
    "            ('sampler1', RandomOverSampler(sampling_strategy= 0.003 , random_state=SEED)),\n",
    "            ('sampler2', RandomUnderSampler(sampling_strategy=0.01, random_state=SEED)),\n",
    "            ('classifier', cb.CatBoostClassifier(**params[\"cat\"])),\n",
    "        ])\n",
    "\n",
    "        cb_model.fit(X_train,y_train)\n",
    "\n",
    "        ### Predictions\n",
    "        cb_y_pred = cb_model.predict_proba(X_val)[:,1]\n",
    "\n",
    "        ### Evaluation\n",
    "        cb_pauc = pauc(y_val,cb_y_pred)\n",
    "        print(f'Fold {fold_id+1} CatBoost : {cb_pauc}')\n",
    "\n",
    "        ### ** Soft ** ###\n",
    "        soft_model = Pipeline([\n",
    "            ('sampler1', RandomOverSampler(sampling_strategy= 0.003 , random_state=SEED)),\n",
    "            ('sampler2', RandomUnderSampler(sampling_strategy=0.01, random_state=SEED)),\n",
    "            ('classifier', VotingClassifier([\n",
    "                ('lgb',lgb.LGBMClassifier(**params[\"lgbm\"])),\n",
    "                ('xgb',xgb.XGBClassifier(**params[\"xgb\"])),\n",
    "                ('cat',cb.CatBoostClassifier(**params[\"cat\"])),\n",
    "            ],voting='soft',weights=[w_lgbm,w_xgb,1.0 - w_lgbm - w_xgb])),\n",
    "        ])\n",
    "\n",
    "        soft_model.fit(X_train,y_train)\n",
    "\n",
    "        ### Predictions\n",
    "        soft_y_pred = soft_model.predict_proba(X_val)[:,1]\n",
    "\n",
    "        ### Evaluation\n",
    "        soft_pauc = pauc(y_val,soft_y_pred)\n",
    "        print(f'Fold {fold_id+1} Soft : {soft_pauc}')\n",
    "\n",
    "        ### ** Stacking ** ###\n",
    "        stacking_model = Pipeline([\n",
    "            ('sampler1', RandomOverSampler(sampling_strategy= 0.003 , random_state=SEED)),\n",
    "            ('sampler2', RandomUnderSampler(sampling_strategy=0.01, random_state=SEED)),\n",
    "            ('classifier', StackingClassifier([\n",
    "                ('lgb',lgb.LGBMClassifier(**params[\"lgbm\"])),\n",
    "                ('xgb',xgb.XGBClassifier(**params[\"xgb\"])),\n",
    "                ('cat',cb.CatBoostClassifier(**params[\"cat\"])),\n",
    "            ],final_estimator=LogisticRegression(),stack_method='predict_proba')),\n",
    "        ])\n",
    "\n",
    "        stacking_model.fit(X_train,y_train)\n",
    "\n",
    "        ### Predictions\n",
    "        stacking_y_pred = stacking_model.predict_proba(X_val)[:,1]\n",
    "\n",
    "        ### Evaluation\n",
    "        stacking_pauc = pauc(y_val,stacking_y_pred)\n",
    "        print(f'Fold {fold_id+1} Stacking : {stacking_pauc}')\n",
    "\n",
    "        ### ** Max ** ###\n",
    "        scores_ = [lgb_pauc,xgb_pauc,cb_pauc]\n",
    "        max_model = [lgb_model,xgb_model,cb_model][scores_.index(max(scores_))]\n",
    "        max_y_pred = max_model.predict_proba(X_val)[:,1]\n",
    "\n",
    "\n",
    "        ### ** Save ** ###\n",
    "        models['lgb'].append(lgb_model)\n",
    "        models['xgb'].append(xgb_model)\n",
    "        models['cat'].append(cb_model)\n",
    "        models['soft'].append(soft_model)\n",
    "        models['stacking'].append(stacking_model)\n",
    "        models['max'].append(max_model)\n",
    "\n",
    "        scores['lgb'].append(lgb_pauc)\n",
    "        scores['xgb'].append(xgb_pauc)\n",
    "        scores['cat'].append(cb_pauc)\n",
    "        scores['soft'].append(soft_pauc)\n",
    "        scores['stacking'].append(stacking_pauc)\n",
    "        scores['max'].append(max(scores_))\n",
    "\n",
    "        preds['lgb'].extend(lgb_y_pred)\n",
    "        preds['xgb'].extend(xgb_y_pred)\n",
    "        preds['cat'].extend(cb_y_pred)\n",
    "        preds['soft'].extend(soft_y_pred)\n",
    "        preds['stacking'].extend(stacking_y_pred)\n",
    "        preds['max'].extend(max_y_pred)\n",
    "\n",
    "        print()\n",
    "\n",
    "    y_val = []\n",
    "\n",
    "    for fold in folds:\n",
    "        y_val.extend(fold['test'][1])\n",
    "\n",
    "    y_val = np.array(y_val)\n",
    "\n",
    "    for model,pred in preds.items():\n",
    "        pred = np.array(pred)\n",
    "        oof_score = pauc(y_val,pred)\n",
    "        print(f'{model} OOF : {oof_score}')\n",
    "\n",
    "    return models,scores,preds,y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"params = {\n",
    "    \"lgbm\" :  {\n",
    "        'objective':        'binary',\n",
    "        'verbosity':        -1,\n",
    "        'n_iter':           500,\n",
    "        'boosting_type':    'gbdt',\n",
    "        'random_state':     SEED,\n",
    "        'lambda_l1':        0.08758718919397321, \n",
    "        'lambda_l2':        0.0039689175176025465, \n",
    "        'learning_rate':    0.03231007103195577, \n",
    "        'max_depth':        4, \n",
    "        'num_leaves':       103, \n",
    "        'colsample_bytree': 0.8329551585827726, \n",
    "        'colsample_bynode': 0.4025961355653304, \n",
    "        'bagging_fraction': 0.7738954452473223, \n",
    "        'bagging_freq':     4, \n",
    "        'min_data_in_leaf': 85\n",
    "    },\n",
    "    \"xgb\" : {\n",
    "        'enable_categorical': True,\n",
    "        'tree_method':        'hist',\n",
    "        'random_state':       SEED,\n",
    "        'learning_rate':      0.08501257473292347, \n",
    "        'lambda':             8.879624125465703, \n",
    "        'alpha':              0.6779926606782505, \n",
    "        'max_depth':          6, \n",
    "        'subsample':          0.6012681388711075, \n",
    "        'colsample_bytree':   0.8437772277074493, \n",
    "        'colsample_bylevel':  0.5476090898823716, \n",
    "        'colsample_bynode':   0.9928601203635129, \n",
    "        'scale_pos_weight':   3.29440313334688,\n",
    "    },\n",
    "    \"cat\" : {\n",
    "        'loss_function':     'Logloss',\n",
    "        'iterations':        200,\n",
    "        'verbose':           False,\n",
    "        'random_state':      SEED,\n",
    "        'max_depth':         7, \n",
    "        'learning_rate':     0.06936242010150652, \n",
    "        'scale_pos_weight':  2.6149345838209532, \n",
    "        'l2_leaf_reg':       6.216113851699493, \n",
    "        'subsample':         0.6249261779711819, \n",
    "        'min_data_in_leaf':  24,\n",
    "        'cat_features':      X_train.columns[X_train.columns.str.startswith('cat')].tolist(),\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"lgbm\" :  {\n",
    "        'random_state': SEED,\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_iter': 217,\n",
    "        'learning_rate': 0.03238691082828724,\n",
    "        'min_data_in_leaf': 93,\n",
    "        'colsample_bytree': 0.6336220063217671,\n",
    "        'colsample_bynode': 0.6449520328952557,\n",
    "        'bagging_fraction': 0.4759532875970691,\n",
    "        'bagging_freq': 5,        \n",
    "        'lambda_l1': 0.26214445542677706,\n",
    "        'lambda_l2': 0.5374677609248407,\n",
    "        'num_leaves': 107,\n",
    "        'max_depth': 6,\n",
    "        'min_child_samples': 38,\n",
    "        'scale_pos_weight': 2.454410437484347,\n",
    "        'verbosity': -1,\n",
    "    },\n",
    "    \"xgb\" : {\n",
    "        'random_state': SEED,\n",
    "        'tree_method': 'hist',\n",
    "        'objective': 'binary:logistic',\n",
    "        'learning_rate': 0.09211299188601348,\n",
    "        'colsample_bytree': 0.8178496272146406,\n",
    "        'colsample_bynode': 0.8688187031865214,\n",
    "        'colsample_bylevel': 0.3476250413253686,\n",
    "        'scale_pos_weight': 2.1101053079075625,\n",
    "        'max_depth': 6,\n",
    "        'subsample': 0.7286594187699229,\n",
    "        'lambda': 4.586386144644716,\n",
    "        'alpha': 0.21956352903435347,\n",
    "        'enable_categorical': True,\n",
    "        'verbosity': 0,\n",
    "    },\n",
    "    \"cat\" : {\n",
    "        'random_state': SEED,\n",
    "        'loss_function': 'Logloss',\n",
    "        'iterations': 240,\n",
    "        'learning_rate': 0.046047767547706654,\n",
    "        'scale_pos_weight': 4.670443106586375,\n",
    "        'reg_lambda': 6.153764402866752,\n",
    "        'subsample': 0.4712307759317672,\n",
    "        'min_data_in_leaf': 26,\n",
    "        'max_depth': 4,\n",
    "        'cat_features': X_train.columns[X_train.columns.str.startswith('cat')].tolist(),\n",
    "        'verbose': False,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 LGBM : 0.18305228906509674\n",
      "Fold 1 XGB : 0.18571332925291573\n",
      "Fold 1 CatBoost : 0.18023608905028252\n",
      "Fold 1 Soft : 0.1836374351812788\n",
      "Fold 1 Stacking : 0.10859052196179377\n",
      "\n",
      "Fold 2 LGBM : 0.1861106407198867\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m models,scores,preds,y_val \u001b[38;5;241m=\u001b[39m train(folds,params\u001b[38;5;241m=\u001b[39mparams)\n",
      "Cell \u001b[0;32mIn[20], line 65\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(folds, params)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m### ** XGB ** ###\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m### Training\u001b[39;00m\n\u001b[1;32m     60\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     61\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampler1\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomOverSampler(sampling_strategy\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.003\u001b[39m , random_state\u001b[38;5;241m=\u001b[39mSEED)),\n\u001b[1;32m     62\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampler2\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomUnderSampler(sampling_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mSEED)),\n\u001b[1;32m     63\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m\"\u001b[39m])),\n\u001b[1;32m     64\u001b[0m ])\n\u001b[0;32m---> 65\u001b[0m xgb_model\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m### Predictions\u001b[39;00m\n\u001b[1;32m     68\u001b[0m xgb_y_pred \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)[:,\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/project/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/project/lib/python3.12/site-packages/imblearn/pipeline.py:326\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    325\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 326\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, yt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/project/lib/python3.12/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/project/lib/python3.12/site-packages/xgboost/sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1491\u001b[0m (\n\u001b[1;32m   1492\u001b[0m     model,\n\u001b[1;32m   1493\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1499\u001b[0m )\n\u001b[1;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1517\u001b[0m )\n\u001b[0;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m   1520\u001b[0m     params,\n\u001b[1;32m   1521\u001b[0m     train_dmatrix,\n\u001b[1;32m   1522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[1;32m   1523\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[1;32m   1524\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds,\n\u001b[1;32m   1525\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[1;32m   1526\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[1;32m   1527\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[1;32m   1528\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   1529\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   1530\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m   1531\u001b[0m )\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/project/lib/python3.12/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/project/lib/python3.12/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/project/lib/python3.12/site-packages/xgboost/core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     _check_call(\n\u001b[0;32m-> 2051\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[1;32m   2052\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   2053\u001b[0m         )\n\u001b[1;32m   2054\u001b[0m     )\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models,scores,preds,y_val = train(folds,params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgb</th>\n",
       "      <th>lgb</th>\n",
       "      <th>cat</th>\n",
       "      <th>soft</th>\n",
       "      <th>stacking</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.185713</td>\n",
       "      <td>0.183052</td>\n",
       "      <td>0.180236</td>\n",
       "      <td>0.183637</td>\n",
       "      <td>0.108591</td>\n",
       "      <td>0.185713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.187129</td>\n",
       "      <td>0.186111</td>\n",
       "      <td>0.185594</td>\n",
       "      <td>0.187303</td>\n",
       "      <td>0.102902</td>\n",
       "      <td>0.187129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.188769</td>\n",
       "      <td>0.191145</td>\n",
       "      <td>0.191438</td>\n",
       "      <td>0.191408</td>\n",
       "      <td>0.138603</td>\n",
       "      <td>0.191438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.165086</td>\n",
       "      <td>0.167145</td>\n",
       "      <td>0.163704</td>\n",
       "      <td>0.169960</td>\n",
       "      <td>0.035475</td>\n",
       "      <td>0.167145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.186950</td>\n",
       "      <td>0.188936</td>\n",
       "      <td>0.189911</td>\n",
       "      <td>0.190397</td>\n",
       "      <td>0.049348</td>\n",
       "      <td>0.189911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.182729</td>\n",
       "      <td>0.183278</td>\n",
       "      <td>0.182177</td>\n",
       "      <td>0.184541</td>\n",
       "      <td>0.086984</td>\n",
       "      <td>0.184267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.008875</td>\n",
       "      <td>0.008512</td>\n",
       "      <td>0.010023</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.038612</td>\n",
       "      <td>0.008795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           xgb       lgb       cat      soft  stacking       max\n",
       "0     0.185713  0.183052  0.180236  0.183637  0.108591  0.185713\n",
       "1     0.187129  0.186111  0.185594  0.187303  0.102902  0.187129\n",
       "2     0.188769  0.191145  0.191438  0.191408  0.138603  0.191438\n",
       "3     0.165086  0.167145  0.163704  0.169960  0.035475  0.167145\n",
       "4     0.186950  0.188936  0.189911  0.190397  0.049348  0.189911\n",
       "mean  0.182729  0.183278  0.182177  0.184541  0.086984  0.184267\n",
       "std   0.008875  0.008512  0.010023  0.007778  0.038612  0.008795"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.DataFrame(scores)\n",
    "eval_df.loc['mean'] = eval_df.mean(axis=0)\n",
    "eval_df.loc['std'] = eval_df.std(axis=0)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise Exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__cols__ = ['age_approx','sex','anatom_site_general','clin_size_long_diam_mm','tbp_lv_A']\n",
    "__cols__ += ['tbp_lv_Aext','tbp_lv_B','tbp_lv_Bext','tbp_lv_C','tbp_lv_Cext','tbp_lv_H','tbp_lv_Hext','tbp_lv_L']\n",
    "__cols__ += ['tbp_lv_Lext','tbp_lv_areaMM2','tbp_lv_area_perim_ratio','tbp_lv_color_std_mean','tbp_lv_deltaA']\n",
    "__cols__ += ['tbp_lv_deltaB','tbp_lv_deltaL','tbp_lv_deltaLB','tbp_lv_deltaLBnorm','tbp_lv_eccentricity','tbp_lv_location']\n",
    "__cols__ += ['tbp_lv_minorAxisMM','tbp_lv_nevi_confidence','tbp_lv_norm_border','tbp_lv_norm_color']\n",
    "__cols__ += ['tbp_lv_perimeterMM','tbp_lv_radial_color_std_max','tbp_lv_stdL','tbp_lv_stdLExt','tbp_lv_symm_2axis']\n",
    "__cols__ += ['tbp_lv_symm_2axis_angle','tbp_lv_x','tbp_lv_y','tbp_lv_z']\n",
    "\n",
    "class ISICDataset(Dataset):\n",
    "\n",
    "    __cols__ = __cols__\n",
    "    \n",
    "    def __init__(self, \n",
    "        hdf5_file : str | h5py.File,\n",
    "        metadata_file : str | pd.DataFrame,\n",
    "        img_transform : Optional[Callable] = None,\n",
    "        metadata_transform : Optional[Callable] = None,\n",
    "        target_transform : Optional[Callable] = None,\n",
    "        return_metadata : bool = False,\n",
    "        target_col : str = \"target\",\n",
    "        mode : str = \"train\"\n",
    "    ) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.hdf5_file = hdf5_file\n",
    "        self.metadata_file = metadata_file\n",
    "        self.img_transform = img_transform\n",
    "        self.target_transform = target_transform\n",
    "        self.metadata_transform = metadata_transform\n",
    "        self.mode = mode\n",
    "        self.target_col = target_col\n",
    "        \n",
    "        self.metadata = pd.read_csv(self.metadata_file) if isinstance(self.metadata_file, str) else self.metadata_file\n",
    "        self.return_metadata = return_metadata\n",
    "        \n",
    "        self.hdf5 = h5py.File(self.hdf5_file, \"r\") if isinstance(self.hdf5_file, str) else self.hdf5_file\n",
    "\n",
    "    def get_labels(self) -> list[int]:\n",
    "        return self.metadata['target'].tolist()\n",
    "       \n",
    "    def __len__(self):\n",
    "        return self.metadata.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index : int) -> tuple[tuple[Any,Any],Any]:\n",
    "        \n",
    "        ### Get the metadata row\n",
    "        row = self.metadata.iloc[index]\n",
    "        \n",
    "        ### Get the target\n",
    "        target = row[self.target_col] if self.mode != \"test\" else 0.0\n",
    "        \n",
    "        ### The image\n",
    "        image_name = row['isic_id']\n",
    "        dataset = self.hdf5[image_name]\n",
    "        buffer = dataset[()]\n",
    "        image_file = io.BytesIO(buffer)\n",
    "        img = Image.open(image_file)\n",
    "        img = np.array(img)\n",
    "\n",
    "        ### The metadata\n",
    "        metadata = row[ISICDataset.__cols__]\n",
    "        \n",
    "        ### Apply the transformations\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        \n",
    "        if self.img_transform is not None:\n",
    "            img = self.img_transform(image=img)\n",
    "            \n",
    "        if self.metadata_transform is not None and self.return_metadata:\n",
    "            metadata = self.metadata_transform(metadata)\n",
    "        \n",
    "        if self.return_metadata:\n",
    "            return (img,metadata), target\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ISICDataset(\n",
    "    hdf5_file=TEST_IMAGES,\n",
    "    metadata_file=TEST_METADATA,\n",
    "    mode=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModule(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "        model_name : str,\n",
    "        num_classes : int = 1,\n",
    "        pretrained : bool = True,\n",
    "        dropout : float = 0.0,\n",
    "    ):\n",
    "\n",
    "        super(BaseModule, self).__init__()\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.num_classes = num_classes\n",
    "        self.pretrained = pretrained\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.model = self.create_model()\n",
    "\n",
    "        if self.dropout > 0.0:\n",
    "\n",
    "            classifier = nn.Sequential(\n",
    "                nn.Dropout(self.dropout),\n",
    "                nn.Linear(self.get_dim(), self.num_classes),\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            classifier = nn.Linear(self.get_dim(), self.num_classes)\n",
    "\n",
    "        self.replace_classifier(classifier)\n",
    "\n",
    "\n",
    "    def create_model(self) -> nn.Module:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def replace_classifier(self, classifier : nn.Module) -> 'BaseModule':\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_dim(self) -> int:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \n",
    "        x = self.model(x)\n",
    "\n",
    "        if self.num_classes == 1:\n",
    "            x = torch.squeeze(x, dim=-1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        x =  self.forward(x)\n",
    "\n",
    "        if self.num_classes == 1:\n",
    "            x = torch.sigmoid(x)\n",
    "        else:\n",
    "            x = torch.softmax(x, dim=-1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def as_backbone(self) -> 'BaseModule':\n",
    "        self.replace_classifier(nn.Identity())\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coat(BaseModule):\n",
    "\n",
    "    __models__ = {\n",
    "        'coat_lite_tiny' : (timm.models.coat.coat_lite_tiny,320),\n",
    "        'coat_lite_mini' : (timm.models.coat.coat_lite_mini,512),\n",
    "    }\n",
    "\n",
    "    def __init__(self, model_name: str, num_classes: int = 1, pretrained: bool = True, dropout: float = 0):\n",
    "        super().__init__(model_name, num_classes, pretrained, dropout)\n",
    "\n",
    "    def create_model(self) -> nn.Module:\n",
    "        model_fn, _ = self.__models__[self.model_name]\n",
    "        model = model_fn(pretrained=self.pretrained)\n",
    "        return model\n",
    "    \n",
    "    def replace_classifier(self, classifier: nn.Module) -> 'Coat':\n",
    "        self.model.head = classifier\n",
    "        return self\n",
    "    \n",
    "    def get_dim(self) -> int:\n",
    "        _, dim = self.__models__[self.model_name]\n",
    "        return dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eva02(BaseModule):\n",
    "\n",
    "    __models = {\n",
    "        'eva02_tiny_patch14_224' : timm.models.eva.eva02_tiny_patch14_224,\n",
    "        'eva02_tiny_patch14_336' : timm.models.eva.eva02_tiny_patch14_336\n",
    "    }\n",
    "\n",
    "    __dims__ = {\n",
    "        'eva02_tiny_patch14_224' : 192,\n",
    "        'eva02_tiny_patch14_336' : 192\n",
    "    }\n",
    "\n",
    "    def __init__(self, model_name: str, num_classes: int = 1, pretrained: bool = True, dropout: float = 0):\n",
    "        super().__init__(model_name, num_classes, pretrained, dropout)\n",
    "\n",
    "    def create_model(self) -> nn.Module:\n",
    "        model_fn = self.__models[self.model_name]\n",
    "        model = model_fn(pretrained=self.pretrained, num_classes=self.num_classes)\n",
    "        return model\n",
    "    \n",
    "    def get_dim(self) -> int:\n",
    "        return self.__dims__[self.model_name]\n",
    "    \n",
    "    def replace_classifier(self, classifier: nn.Module) -> 'Eva02':\n",
    "        self.model.head = classifier\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name : str):\n",
    "\n",
    "    if model_name.startswith('coat'):\n",
    "        return Coat(model_name,pretrained=False)\n",
    "    elif model_name.startswith('eva02'):\n",
    "        return Eva02(model_name,pretrained=False)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\n",
    "        \"model_name\" : \"coat_lite_tiny\",\n",
    "        \"checkpoints\" : \"/home/abdelnour/Documents/projects/skin-cancer-detection/expirements/coat_lite_tiny_2/checkpoints\",\n",
    "        \"feature_name\" : \"coat_lite_tiny_2\",\n",
    "        \"transforms\" : A.Compose([\n",
    "            A.Resize(224,224,p=1.0),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225),max_pixel_value=255.0,p=1.0),\n",
    "            AP.ToTensorV2(p=1.0),\n",
    "        ],p=1.0),\n",
    "        \"order\" : ['fold_0/model_fold=0.pt','fold_1/model_fold=1.pt','fold_2/model_fold=2.pt','fold_3/model_fold=3.pt','fold_4/model_fold=4.pt'],\n",
    "    },\n",
    "    {\n",
    "        \"model_name\" : \"eva02_tiny_patch14_224\",\n",
    "        \"checkpoints\" : \"/home/abdelnour/Documents/projects/skin-cancer-detection/expirements/eva02_224/checkpoints\",\n",
    "        \"feature_name\" : \"eva02_tiny_patch14_224\",\n",
    "        \"transforms\" : A.Compose([\n",
    "            A.Resize(224,224,p=1.0),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225),max_pixel_value=255.0,p=1.0),\n",
    "            AP.ToTensorV2(p=1.0),\n",
    "        ],p=1.0),\n",
    "        \"order\" : ['fold_0/model_fold=0.pt','fold_1/model_fold=1.pt','fold_2/model_fold=2.pt','fold_3/model_fold=3.pt','fold_4/model_fold=4.pt'],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(model_type : str,checkpoints_dir : str, files : list[str]):\n",
    "    \n",
    "    models = []\n",
    "        \n",
    "    for file in tqdm(files):\n",
    "        \n",
    "        model = create_model(model_type)\n",
    "        \n",
    "        state_dict = torch.load(os.path.join(checkpoints_dir, file),map_location=DEVICE)\n",
    "        msg = model.load_state_dict(state_dict,strict=False)\n",
    "\n",
    "        print(msg)\n",
    "        \n",
    "        model = model.to(DEVICE)\n",
    "        model = model.eval()\n",
    "        \n",
    "        models.append(model)\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    prefetch_factor=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models : list[torch.nn.Module], dataloader: DataLoader):\n",
    "\n",
    "    result = dict()\n",
    "        \n",
    "    for i,_ in enumerate(models):\n",
    "        result[f\"y_pred_{i}\"] = []\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        \n",
    "        for x,_ in tqdm(dataloader):\n",
    "\n",
    "            x = x[\"image\"].to(DEVICE)\n",
    "\n",
    "            for i,model in enumerate(models):\n",
    "                y_hat = model.predict(x).detach().cpu().numpy()\n",
    "                result[f\"y_pred_{i}\"].extend(y_hat)\n",
    "            \n",
    "    result['isic_id'] = dataloader.dataset.metadata['isic_id']\n",
    "\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(configs : list[dict]):\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for config in configs:\n",
    "\n",
    "        ### Preprocessing\n",
    "        dataset.img_transform = config['transforms']\n",
    "        \n",
    "        ### Load the models\n",
    "        models = load_models(config['model_name'],config['checkpoints'],config['order'])\n",
    "\n",
    "        ### Predict\n",
    "        preds = predict(models,dataloader)\n",
    "\n",
    "        ### Save the features\n",
    "        features.append(pd.DataFrame({\n",
    "            'isic_id' : preds['isic_id'],\n",
    "            config['feature_name'] : preds.drop(columns='isic_id').mean(axis=1)\n",
    "        }))\n",
    "\n",
    "    merged_features = features[0]\n",
    "\n",
    "    for feature in features[1:]:\n",
    "        merged_features = merged_features.merge(feature,on='isic_id')\n",
    "\n",
    "    return merged_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f849497cfe8437688e39497468f5f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e886a80b5213449aa59ead8501fb11e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d78ccff86745c19c19083eeb4b6c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714a2cb4395146749448215db5172a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features = get_features(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>coat_lite_tiny_2</th>\n",
       "      <th>eva02_tiny_patch14_224</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>0.007220</td>\n",
       "      <td>0.009390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.000969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id  coat_lite_tiny_2  eva02_tiny_patch14_224\n",
       "0  ISIC_0015657          0.007220                0.009390\n",
       "1  ISIC_0015729          0.000469                0.001132\n",
       "2  ISIC_0015740          0.000926                0.000969"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df,_),_ = prepare_data(test_df,test_features,preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    models : list,\n",
    "    test_df : pd.DataFrame,\n",
    "):\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    for i in range(5):\n",
    "        pred = w_lgbm * models['lgb'][i].predict_proba(test_df)[:,1] \\\n",
    "            + (1 - w_xgb - w_lgbm) * models['cat'][i].predict_proba(test_df)[:,1] \\\n",
    "            + w_xgb * models['xgb'][i].predict_proba(test_df)[:,1]\n",
    "        preds.append(pred)\n",
    "\n",
    "    preds = np.mean(preds,axis=0)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(models,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'isic_id' : dataset.metadata.isic_id,\n",
    "    'target' : preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>0.001045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740</td>\n",
       "      <td>0.000360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id    target\n",
       "0  ISIC_0015657  0.001045\n",
       "1  ISIC_0015729  0.000259\n",
       "2  ISIC_0015740  0.000360"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
